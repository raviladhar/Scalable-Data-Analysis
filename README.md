# Scalable-Data-Analysis
Analysis & Design: For my project I am analyzing few things like finding out the trajectory stops from where it started, and where it stops for some time, so I can segment the trajectory data into multiple sub trajectories. Probably my first step would be to figure out how can I use the multiprocessing for this project, so I can efficiently execute multiple tasks parallelly. Second step would be to find out the stops based on time and distance, where I can set up the distance threshold to segment it into sub trajectory. Such as where the voyage stayed and for how long it was there, or it was moving continuously with some speed.
Scalability Challenges: The data I am working on is a large dataset, and for this large data my machine is not able to handle the processing and analyzing. I need to scale the processing such as through multiprocessing where I can distribute the data on multiple cores in order to enhance the execution power.
Originally my data is in gdb format, which is around 3-GB, which my machine is unable to convert the parquet table format, so I can use the multiprocessing on the server to convert the data from gdb to parquet and can use it for my further analysis
